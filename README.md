# palpable_ai
for palp shennanigans (pompeii artistic landscapes propject, [palp.art](https://palp.art)

1. use palp_to_generated-qa-pairs-via-gemini.ipynb to search for images tagged with concepts like motif, mythological character, etc. This notebook will download those images and the associated descriptions. Then, in the second part, it will pass those images and descriptions to Gemini (try Gemini 2; make sure you have a key; don't save the key in the notebook but rather in the environment or keys section in google colab) and ask Gemini to use both the image AND the description to come up with appropriate question and answer pairs for each image, ie, the kinds of questions you as an art historian or archaeologist want to ask about images - or a folder of images - for sorting, generating metadata, etc.
2. You should then use the 'filter-for-inappropriate-questions' notebook to try to remove questions that aren't useful for training a model, eg, 'in what work was this photo published', that sort of thing. It'll create two csvs, moving the ones it identifies from your list into a new document. Cut n' paste as appropriate.
3. Use the copy_finetune_idefics notebook to create the dataset that will get pushed to your huggingface account. You'll need a huggingface token. The two rounds of dataset creation created subtly different arrangements of 'conversations', depending on the model. Once these are pushed to huggingface, you can continue to use this notebook to train a model and test it out. Given that you're probably using free Google colab, you can't really train it enough for best results, but still, you can see how it goes.
4. you vsn use the pixtral notebook from unsloth to try training that model (You can try finetuning other models using the https://huggingface.co/datasets/sgraham/pixtral_QA_palp_test dataset, see: https://docs.unsloth.ai/get-started/unsloth-notebooks

Datasets and my fast-and-dirty trained modesl are available at my hugginface, [https://huggingface.co](https://huggingface.co/sgraham)
